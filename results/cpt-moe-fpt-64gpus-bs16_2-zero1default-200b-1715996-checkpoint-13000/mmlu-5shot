{
  "results": {
    "hendrycksTest-abstract_algebra": {
      "acc": 0.18,
      "acc_stderr": 0.038612291966536955,
      "acc_norm": 0.18,
      "acc_norm_stderr": 0.038612291966536955
    },
    "hendrycksTest-anatomy": {
      "acc": 0.21481481481481482,
      "acc_stderr": 0.035478541985608285,
      "acc_norm": 0.21481481481481482,
      "acc_norm_stderr": 0.035478541985608285
    },
    "hendrycksTest-astronomy": {
      "acc": 0.18421052631578946,
      "acc_stderr": 0.0315469804508223,
      "acc_norm": 0.18421052631578946,
      "acc_norm_stderr": 0.0315469804508223
    },
    "hendrycksTest-business_ethics": {
      "acc": 0.25,
      "acc_stderr": 0.04351941398892446,
      "acc_norm": 0.25,
      "acc_norm_stderr": 0.04351941398892446
    },
    "hendrycksTest-clinical_knowledge": {
      "acc": 0.24150943396226415,
      "acc_stderr": 0.026341480371118355,
      "acc_norm": 0.24150943396226415,
      "acc_norm_stderr": 0.026341480371118355
    },
    "hendrycksTest-college_biology": {
      "acc": 0.22916666666666666,
      "acc_stderr": 0.035146974678623884,
      "acc_norm": 0.22916666666666666,
      "acc_norm_stderr": 0.035146974678623884
    },
    "hendrycksTest-college_chemistry": {
      "acc": 0.21,
      "acc_stderr": 0.040936018074033256,
      "acc_norm": 0.21,
      "acc_norm_stderr": 0.040936018074033256
    },
    "hendrycksTest-college_computer_science": {
      "acc": 0.34,
      "acc_stderr": 0.04760952285695235,
      "acc_norm": 0.34,
      "acc_norm_stderr": 0.04760952285695235
    },
    "hendrycksTest-college_mathematics": {
      "acc": 0.28,
      "acc_stderr": 0.04512608598542127,
      "acc_norm": 0.28,
      "acc_norm_stderr": 0.04512608598542127
    },
    "hendrycksTest-college_medicine": {
      "acc": 0.28901734104046245,
      "acc_stderr": 0.03456425745087,
      "acc_norm": 0.28901734104046245,
      "acc_norm_stderr": 0.03456425745087
    },
    "hendrycksTest-college_physics": {
      "acc": 0.28431372549019607,
      "acc_stderr": 0.04488482852329017,
      "acc_norm": 0.28431372549019607,
      "acc_norm_stderr": 0.04488482852329017
    },
    "hendrycksTest-computer_security": {
      "acc": 0.31,
      "acc_stderr": 0.04648231987117316,
      "acc_norm": 0.31,
      "acc_norm_stderr": 0.04648231987117316
    },
    "hendrycksTest-conceptual_physics": {
      "acc": 0.30638297872340425,
      "acc_stderr": 0.03013590647851756,
      "acc_norm": 0.30638297872340425,
      "acc_norm_stderr": 0.03013590647851756
    },
    "hendrycksTest-econometrics": {
      "acc": 0.2807017543859649,
      "acc_stderr": 0.042270544512322004,
      "acc_norm": 0.2807017543859649,
      "acc_norm_stderr": 0.042270544512322004
    },
    "hendrycksTest-electrical_engineering": {
      "acc": 0.19310344827586207,
      "acc_stderr": 0.032894455221274016,
      "acc_norm": 0.19310344827586207,
      "acc_norm_stderr": 0.032894455221274016
    },
    "hendrycksTest-elementary_mathematics": {
      "acc": 0.2724867724867725,
      "acc_stderr": 0.02293097307163335,
      "acc_norm": 0.2724867724867725,
      "acc_norm_stderr": 0.02293097307163335
    },
    "hendrycksTest-formal_logic": {
      "acc": 0.2777777777777778,
      "acc_stderr": 0.04006168083848879,
      "acc_norm": 0.2777777777777778,
      "acc_norm_stderr": 0.04006168083848879
    },
    "hendrycksTest-global_facts": {
      "acc": 0.3,
      "acc_stderr": 0.046056618647183814,
      "acc_norm": 0.3,
      "acc_norm_stderr": 0.046056618647183814
    },
    "hendrycksTest-high_school_biology": {
      "acc": 0.23870967741935484,
      "acc_stderr": 0.024251071262208834,
      "acc_norm": 0.23870967741935484,
      "acc_norm_stderr": 0.024251071262208834
    },
    "hendrycksTest-high_school_chemistry": {
      "acc": 0.23645320197044334,
      "acc_stderr": 0.02989611429173355,
      "acc_norm": 0.23645320197044334,
      "acc_norm_stderr": 0.02989611429173355
    },
    "hendrycksTest-high_school_computer_science": {
      "acc": 0.27,
      "acc_stderr": 0.044619604333847394,
      "acc_norm": 0.27,
      "acc_norm_stderr": 0.044619604333847394
    },
    "hendrycksTest-high_school_european_history": {
      "acc": 0.22424242424242424,
      "acc_stderr": 0.03256866661681102,
      "acc_norm": 0.22424242424242424,
      "acc_norm_stderr": 0.03256866661681102
    },
    "hendrycksTest-high_school_geography": {
      "acc": 0.19696969696969696,
      "acc_stderr": 0.028335609732463348,
      "acc_norm": 0.19696969696969696,
      "acc_norm_stderr": 0.028335609732463348
    },
    "hendrycksTest-high_school_government_and_politics": {
      "acc": 0.26424870466321243,
      "acc_stderr": 0.03182155050916646,
      "acc_norm": 0.26424870466321243,
      "acc_norm_stderr": 0.03182155050916646
    },
    "hendrycksTest-high_school_macroeconomics": {
      "acc": 0.2948717948717949,
      "acc_stderr": 0.023119362758232294,
      "acc_norm": 0.2948717948717949,
      "acc_norm_stderr": 0.023119362758232294
    },
    "hendrycksTest-high_school_mathematics": {
      "acc": 0.26296296296296295,
      "acc_stderr": 0.02684205787383371,
      "acc_norm": 0.26296296296296295,
      "acc_norm_stderr": 0.02684205787383371
    },
    "hendrycksTest-high_school_microeconomics": {
      "acc": 0.29831932773109243,
      "acc_stderr": 0.02971914287634287,
      "acc_norm": 0.29831932773109243,
      "acc_norm_stderr": 0.02971914287634287
    },
    "hendrycksTest-high_school_physics": {
      "acc": 0.31788079470198677,
      "acc_stderr": 0.03802039760107903,
      "acc_norm": 0.31788079470198677,
      "acc_norm_stderr": 0.03802039760107903
    },
    "hendrycksTest-high_school_psychology": {
      "acc": 0.23853211009174313,
      "acc_stderr": 0.018272575810231853,
      "acc_norm": 0.23853211009174313,
      "acc_norm_stderr": 0.018272575810231853
    },
    "hendrycksTest-high_school_statistics": {
      "acc": 0.3101851851851852,
      "acc_stderr": 0.03154696285656628,
      "acc_norm": 0.3101851851851852,
      "acc_norm_stderr": 0.03154696285656628
    },
    "hendrycksTest-high_school_us_history": {
      "acc": 0.28431372549019607,
      "acc_stderr": 0.03166009679399812,
      "acc_norm": 0.28431372549019607,
      "acc_norm_stderr": 0.03166009679399812
    },
    "hendrycksTest-high_school_world_history": {
      "acc": 0.28270042194092826,
      "acc_stderr": 0.029312814153955924,
      "acc_norm": 0.28270042194092826,
      "acc_norm_stderr": 0.029312814153955924
    },
    "hendrycksTest-human_aging": {
      "acc": 0.3004484304932735,
      "acc_stderr": 0.030769352008229143,
      "acc_norm": 0.3004484304932735,
      "acc_norm_stderr": 0.030769352008229143
    },
    "hendrycksTest-human_sexuality": {
      "acc": 0.21374045801526717,
      "acc_stderr": 0.0359546161177469,
      "acc_norm": 0.21374045801526717,
      "acc_norm_stderr": 0.0359546161177469
    },
    "hendrycksTest-international_law": {
      "acc": 0.36363636363636365,
      "acc_stderr": 0.043913262867240704,
      "acc_norm": 0.36363636363636365,
      "acc_norm_stderr": 0.043913262867240704
    },
    "hendrycksTest-jurisprudence": {
      "acc": 0.2962962962962963,
      "acc_stderr": 0.04414343666854933,
      "acc_norm": 0.2962962962962963,
      "acc_norm_stderr": 0.04414343666854933
    },
    "hendrycksTest-logical_fallacies": {
      "acc": 0.2147239263803681,
      "acc_stderr": 0.03226219377286774,
      "acc_norm": 0.2147239263803681,
      "acc_norm_stderr": 0.03226219377286774
    },
    "hendrycksTest-machine_learning": {
      "acc": 0.22321428571428573,
      "acc_stderr": 0.039523019677025116,
      "acc_norm": 0.22321428571428573,
      "acc_norm_stderr": 0.039523019677025116
    },
    "hendrycksTest-management": {
      "acc": 0.2524271844660194,
      "acc_stderr": 0.04301250399690877,
      "acc_norm": 0.2524271844660194,
      "acc_norm_stderr": 0.04301250399690877
    },
    "hendrycksTest-marketing": {
      "acc": 0.27350427350427353,
      "acc_stderr": 0.029202540153431163,
      "acc_norm": 0.27350427350427353,
      "acc_norm_stderr": 0.029202540153431163
    },
    "hendrycksTest-medical_genetics": {
      "acc": 0.26,
      "acc_stderr": 0.044084400227680794,
      "acc_norm": 0.26,
      "acc_norm_stderr": 0.044084400227680794
    },
    "hendrycksTest-miscellaneous": {
      "acc": 0.25798212005108556,
      "acc_stderr": 0.01564583018834895,
      "acc_norm": 0.25798212005108556,
      "acc_norm_stderr": 0.01564583018834895
    },
    "hendrycksTest-moral_disputes": {
      "acc": 0.2543352601156069,
      "acc_stderr": 0.023445826276545543,
      "acc_norm": 0.2543352601156069,
      "acc_norm_stderr": 0.023445826276545543
    },
    "hendrycksTest-moral_scenarios": {
      "acc": 0.2324022346368715,
      "acc_stderr": 0.014125968754673394,
      "acc_norm": 0.2324022346368715,
      "acc_norm_stderr": 0.014125968754673394
    },
    "hendrycksTest-nutrition": {
      "acc": 0.29411764705882354,
      "acc_stderr": 0.026090162504279046,
      "acc_norm": 0.29411764705882354,
      "acc_norm_stderr": 0.026090162504279046
    },
    "hendrycksTest-philosophy": {
      "acc": 0.2861736334405145,
      "acc_stderr": 0.02567025924218894,
      "acc_norm": 0.2861736334405145,
      "acc_norm_stderr": 0.02567025924218894
    },
    "hendrycksTest-prehistory": {
      "acc": 0.24382716049382716,
      "acc_stderr": 0.023891879541959607,
      "acc_norm": 0.24382716049382716,
      "acc_norm_stderr": 0.023891879541959607
    },
    "hendrycksTest-professional_accounting": {
      "acc": 0.2624113475177305,
      "acc_stderr": 0.026244920349843007,
      "acc_norm": 0.2624113475177305,
      "acc_norm_stderr": 0.026244920349843007
    },
    "hendrycksTest-professional_law": {
      "acc": 0.25488917861799215,
      "acc_stderr": 0.011130509812662965,
      "acc_norm": 0.25488917861799215,
      "acc_norm_stderr": 0.011130509812662965
    },
    "hendrycksTest-professional_medicine": {
      "acc": 0.44485294117647056,
      "acc_stderr": 0.030187532060329376,
      "acc_norm": 0.44485294117647056,
      "acc_norm_stderr": 0.030187532060329376
    },
    "hendrycksTest-professional_psychology": {
      "acc": 0.24836601307189543,
      "acc_stderr": 0.017479487001364764,
      "acc_norm": 0.24836601307189543,
      "acc_norm_stderr": 0.017479487001364764
    },
    "hendrycksTest-public_relations": {
      "acc": 0.34545454545454546,
      "acc_stderr": 0.04554619617541054,
      "acc_norm": 0.34545454545454546,
      "acc_norm_stderr": 0.04554619617541054
    },
    "hendrycksTest-security_studies": {
      "acc": 0.3224489795918367,
      "acc_stderr": 0.029923100563683906,
      "acc_norm": 0.3224489795918367,
      "acc_norm_stderr": 0.029923100563683906
    },
    "hendrycksTest-sociology": {
      "acc": 0.23880597014925373,
      "acc_stderr": 0.03014777593540922,
      "acc_norm": 0.23880597014925373,
      "acc_norm_stderr": 0.03014777593540922
    },
    "hendrycksTest-us_foreign_policy": {
      "acc": 0.25,
      "acc_stderr": 0.04351941398892446,
      "acc_norm": 0.25,
      "acc_norm_stderr": 0.04351941398892446
    },
    "hendrycksTest-virology": {
      "acc": 0.25903614457831325,
      "acc_stderr": 0.034106466140718564,
      "acc_norm": 0.25903614457831325,
      "acc_norm_stderr": 0.034106466140718564
    },
    "hendrycksTest-world_religions": {
      "acc": 0.30409356725146197,
      "acc_stderr": 0.03528211258245231,
      "acc_norm": 0.30409356725146197,
      "acc_norm_stderr": 0.03528211258245231
    }
  },
  "versions": {
    "hendrycksTest-abstract_algebra": 1,
    "hendrycksTest-anatomy": 1,
    "hendrycksTest-astronomy": 1,
    "hendrycksTest-business_ethics": 1,
    "hendrycksTest-clinical_knowledge": 1,
    "hendrycksTest-college_biology": 1,
    "hendrycksTest-college_chemistry": 1,
    "hendrycksTest-college_computer_science": 1,
    "hendrycksTest-college_mathematics": 1,
    "hendrycksTest-college_medicine": 1,
    "hendrycksTest-college_physics": 1,
    "hendrycksTest-computer_security": 1,
    "hendrycksTest-conceptual_physics": 1,
    "hendrycksTest-econometrics": 1,
    "hendrycksTest-electrical_engineering": 1,
    "hendrycksTest-elementary_mathematics": 1,
    "hendrycksTest-formal_logic": 1,
    "hendrycksTest-global_facts": 1,
    "hendrycksTest-high_school_biology": 1,
    "hendrycksTest-high_school_chemistry": 1,
    "hendrycksTest-high_school_computer_science": 1,
    "hendrycksTest-high_school_european_history": 1,
    "hendrycksTest-high_school_geography": 1,
    "hendrycksTest-high_school_government_and_politics": 1,
    "hendrycksTest-high_school_macroeconomics": 1,
    "hendrycksTest-high_school_mathematics": 1,
    "hendrycksTest-high_school_microeconomics": 1,
    "hendrycksTest-high_school_physics": 1,
    "hendrycksTest-high_school_psychology": 1,
    "hendrycksTest-high_school_statistics": 1,
    "hendrycksTest-high_school_us_history": 1,
    "hendrycksTest-high_school_world_history": 1,
    "hendrycksTest-human_aging": 1,
    "hendrycksTest-human_sexuality": 1,
    "hendrycksTest-international_law": 1,
    "hendrycksTest-jurisprudence": 1,
    "hendrycksTest-logical_fallacies": 1,
    "hendrycksTest-machine_learning": 1,
    "hendrycksTest-management": 1,
    "hendrycksTest-marketing": 1,
    "hendrycksTest-medical_genetics": 1,
    "hendrycksTest-miscellaneous": 1,
    "hendrycksTest-moral_disputes": 1,
    "hendrycksTest-moral_scenarios": 1,
    "hendrycksTest-nutrition": 1,
    "hendrycksTest-philosophy": 1,
    "hendrycksTest-prehistory": 1,
    "hendrycksTest-professional_accounting": 1,
    "hendrycksTest-professional_law": 1,
    "hendrycksTest-professional_medicine": 1,
    "hendrycksTest-professional_psychology": 1,
    "hendrycksTest-public_relations": 1,
    "hendrycksTest-security_studies": 1,
    "hendrycksTest-sociology": 1,
    "hendrycksTest-us_foreign_policy": 1,
    "hendrycksTest-virology": 1,
    "hendrycksTest-world_religions": 1
  },
  "config": {
    "model": "llama-moe-causal",
    "model_args": "pretrained=/mnt/petrelfs/zhutong/smoe/outputs/cpt-moe-fpt-64gpus-bs16_2-zero1default-200b-1715996/checkpoint-13000,use_accelerate=True",
    "num_fewshot": 5,
    "batch_size": "2",
    "batch_sizes": [],
    "device": null,
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}