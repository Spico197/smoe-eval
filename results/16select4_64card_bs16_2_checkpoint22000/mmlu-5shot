{
  "results": {
    "hendrycksTest-abstract_algebra": {
      "acc": 0.23,
      "acc_stderr": 0.04229525846816506,
      "acc_norm": 0.23,
      "acc_norm_stderr": 0.04229525846816506
    },
    "hendrycksTest-anatomy": {
      "acc": 0.2518518518518518,
      "acc_stderr": 0.03749850709174023,
      "acc_norm": 0.2518518518518518,
      "acc_norm_stderr": 0.03749850709174023
    },
    "hendrycksTest-astronomy": {
      "acc": 0.26973684210526316,
      "acc_stderr": 0.03611780560284898,
      "acc_norm": 0.26973684210526316,
      "acc_norm_stderr": 0.03611780560284898
    },
    "hendrycksTest-business_ethics": {
      "acc": 0.16,
      "acc_stderr": 0.03684529491774709,
      "acc_norm": 0.16,
      "acc_norm_stderr": 0.03684529491774709
    },
    "hendrycksTest-clinical_knowledge": {
      "acc": 0.2943396226415094,
      "acc_stderr": 0.028049186315695248,
      "acc_norm": 0.2943396226415094,
      "acc_norm_stderr": 0.028049186315695248
    },
    "hendrycksTest-college_biology": {
      "acc": 0.2916666666666667,
      "acc_stderr": 0.038009680605548574,
      "acc_norm": 0.2916666666666667,
      "acc_norm_stderr": 0.038009680605548574
    },
    "hendrycksTest-college_chemistry": {
      "acc": 0.33,
      "acc_stderr": 0.04725815626252604,
      "acc_norm": 0.33,
      "acc_norm_stderr": 0.04725815626252604
    },
    "hendrycksTest-college_computer_science": {
      "acc": 0.34,
      "acc_stderr": 0.04760952285695235,
      "acc_norm": 0.34,
      "acc_norm_stderr": 0.04760952285695235
    },
    "hendrycksTest-college_mathematics": {
      "acc": 0.31,
      "acc_stderr": 0.04648231987117316,
      "acc_norm": 0.31,
      "acc_norm_stderr": 0.04648231987117316
    },
    "hendrycksTest-college_medicine": {
      "acc": 0.3699421965317919,
      "acc_stderr": 0.036812296333943194,
      "acc_norm": 0.3699421965317919,
      "acc_norm_stderr": 0.036812296333943194
    },
    "hendrycksTest-college_physics": {
      "acc": 0.2647058823529412,
      "acc_stderr": 0.04389869956808778,
      "acc_norm": 0.2647058823529412,
      "acc_norm_stderr": 0.04389869956808778
    },
    "hendrycksTest-computer_security": {
      "acc": 0.19,
      "acc_stderr": 0.03942772444036622,
      "acc_norm": 0.19,
      "acc_norm_stderr": 0.03942772444036622
    },
    "hendrycksTest-conceptual_physics": {
      "acc": 0.28085106382978725,
      "acc_stderr": 0.02937917046412482,
      "acc_norm": 0.28085106382978725,
      "acc_norm_stderr": 0.02937917046412482
    },
    "hendrycksTest-econometrics": {
      "acc": 0.2543859649122807,
      "acc_stderr": 0.040969851398436716,
      "acc_norm": 0.2543859649122807,
      "acc_norm_stderr": 0.040969851398436716
    },
    "hendrycksTest-electrical_engineering": {
      "acc": 0.25517241379310346,
      "acc_stderr": 0.03632984052707842,
      "acc_norm": 0.25517241379310346,
      "acc_norm_stderr": 0.03632984052707842
    },
    "hendrycksTest-elementary_mathematics": {
      "acc": 0.26455026455026454,
      "acc_stderr": 0.022717467897708617,
      "acc_norm": 0.26455026455026454,
      "acc_norm_stderr": 0.022717467897708617
    },
    "hendrycksTest-formal_logic": {
      "acc": 0.24603174603174602,
      "acc_stderr": 0.03852273364924315,
      "acc_norm": 0.24603174603174602,
      "acc_norm_stderr": 0.03852273364924315
    },
    "hendrycksTest-global_facts": {
      "acc": 0.3,
      "acc_stderr": 0.046056618647183814,
      "acc_norm": 0.3,
      "acc_norm_stderr": 0.046056618647183814
    },
    "hendrycksTest-high_school_biology": {
      "acc": 0.3064516129032258,
      "acc_stderr": 0.026226485652553883,
      "acc_norm": 0.3064516129032258,
      "acc_norm_stderr": 0.026226485652553883
    },
    "hendrycksTest-high_school_chemistry": {
      "acc": 0.2561576354679803,
      "acc_stderr": 0.030712730070982592,
      "acc_norm": 0.2561576354679803,
      "acc_norm_stderr": 0.030712730070982592
    },
    "hendrycksTest-high_school_computer_science": {
      "acc": 0.2,
      "acc_stderr": 0.04020151261036845,
      "acc_norm": 0.2,
      "acc_norm_stderr": 0.04020151261036845
    },
    "hendrycksTest-high_school_european_history": {
      "acc": 0.2545454545454545,
      "acc_stderr": 0.03401506715249039,
      "acc_norm": 0.2545454545454545,
      "acc_norm_stderr": 0.03401506715249039
    },
    "hendrycksTest-high_school_geography": {
      "acc": 0.32323232323232326,
      "acc_stderr": 0.03332299921070644,
      "acc_norm": 0.32323232323232326,
      "acc_norm_stderr": 0.03332299921070644
    },
    "hendrycksTest-high_school_government_and_politics": {
      "acc": 0.32642487046632124,
      "acc_stderr": 0.033840286211432945,
      "acc_norm": 0.32642487046632124,
      "acc_norm_stderr": 0.033840286211432945
    },
    "hendrycksTest-high_school_macroeconomics": {
      "acc": 0.358974358974359,
      "acc_stderr": 0.024321738484602364,
      "acc_norm": 0.358974358974359,
      "acc_norm_stderr": 0.024321738484602364
    },
    "hendrycksTest-high_school_mathematics": {
      "acc": 0.24814814814814815,
      "acc_stderr": 0.0263357394040558,
      "acc_norm": 0.24814814814814815,
      "acc_norm_stderr": 0.0263357394040558
    },
    "hendrycksTest-high_school_microeconomics": {
      "acc": 0.3319327731092437,
      "acc_stderr": 0.030588697013783663,
      "acc_norm": 0.3319327731092437,
      "acc_norm_stderr": 0.030588697013783663
    },
    "hendrycksTest-high_school_physics": {
      "acc": 0.2582781456953642,
      "acc_stderr": 0.035737053147634576,
      "acc_norm": 0.2582781456953642,
      "acc_norm_stderr": 0.035737053147634576
    },
    "hendrycksTest-high_school_psychology": {
      "acc": 0.344954128440367,
      "acc_stderr": 0.020380605405066962,
      "acc_norm": 0.344954128440367,
      "acc_norm_stderr": 0.020380605405066962
    },
    "hendrycksTest-high_school_statistics": {
      "acc": 0.44907407407407407,
      "acc_stderr": 0.03392238405321617,
      "acc_norm": 0.44907407407407407,
      "acc_norm_stderr": 0.03392238405321617
    },
    "hendrycksTest-high_school_us_history": {
      "acc": 0.24509803921568626,
      "acc_stderr": 0.03019028245350195,
      "acc_norm": 0.24509803921568626,
      "acc_norm_stderr": 0.03019028245350195
    },
    "hendrycksTest-high_school_world_history": {
      "acc": 0.23628691983122363,
      "acc_stderr": 0.02765215314415926,
      "acc_norm": 0.23628691983122363,
      "acc_norm_stderr": 0.02765215314415926
    },
    "hendrycksTest-human_aging": {
      "acc": 0.14798206278026907,
      "acc_stderr": 0.02383155715761354,
      "acc_norm": 0.14798206278026907,
      "acc_norm_stderr": 0.02383155715761354
    },
    "hendrycksTest-human_sexuality": {
      "acc": 0.2748091603053435,
      "acc_stderr": 0.039153454088478354,
      "acc_norm": 0.2748091603053435,
      "acc_norm_stderr": 0.039153454088478354
    },
    "hendrycksTest-international_law": {
      "acc": 0.15702479338842976,
      "acc_stderr": 0.0332124484254713,
      "acc_norm": 0.15702479338842976,
      "acc_norm_stderr": 0.0332124484254713
    },
    "hendrycksTest-jurisprudence": {
      "acc": 0.24074074074074073,
      "acc_stderr": 0.04133119440243839,
      "acc_norm": 0.24074074074074073,
      "acc_norm_stderr": 0.04133119440243839
    },
    "hendrycksTest-logical_fallacies": {
      "acc": 0.3067484662576687,
      "acc_stderr": 0.03623089915724148,
      "acc_norm": 0.3067484662576687,
      "acc_norm_stderr": 0.03623089915724148
    },
    "hendrycksTest-machine_learning": {
      "acc": 0.22321428571428573,
      "acc_stderr": 0.039523019677025116,
      "acc_norm": 0.22321428571428573,
      "acc_norm_stderr": 0.039523019677025116
    },
    "hendrycksTest-management": {
      "acc": 0.3106796116504854,
      "acc_stderr": 0.0458212416016155,
      "acc_norm": 0.3106796116504854,
      "acc_norm_stderr": 0.0458212416016155
    },
    "hendrycksTest-marketing": {
      "acc": 0.2564102564102564,
      "acc_stderr": 0.028605953702004253,
      "acc_norm": 0.2564102564102564,
      "acc_norm_stderr": 0.028605953702004253
    },
    "hendrycksTest-medical_genetics": {
      "acc": 0.29,
      "acc_stderr": 0.045604802157206845,
      "acc_norm": 0.29,
      "acc_norm_stderr": 0.045604802157206845
    },
    "hendrycksTest-miscellaneous": {
      "acc": 0.20178799489144317,
      "acc_stderr": 0.014351702181636873,
      "acc_norm": 0.20178799489144317,
      "acc_norm_stderr": 0.014351702181636873
    },
    "hendrycksTest-moral_disputes": {
      "acc": 0.2543352601156069,
      "acc_stderr": 0.023445826276545543,
      "acc_norm": 0.2543352601156069,
      "acc_norm_stderr": 0.023445826276545543
    },
    "hendrycksTest-moral_scenarios": {
      "acc": 0.23798882681564246,
      "acc_stderr": 0.014242630070574904,
      "acc_norm": 0.23798882681564246,
      "acc_norm_stderr": 0.014242630070574904
    },
    "hendrycksTest-nutrition": {
      "acc": 0.26143790849673204,
      "acc_stderr": 0.025160998214292456,
      "acc_norm": 0.26143790849673204,
      "acc_norm_stderr": 0.025160998214292456
    },
    "hendrycksTest-philosophy": {
      "acc": 0.3054662379421222,
      "acc_stderr": 0.02616058445014049,
      "acc_norm": 0.3054662379421222,
      "acc_norm_stderr": 0.02616058445014049
    },
    "hendrycksTest-prehistory": {
      "acc": 0.2623456790123457,
      "acc_stderr": 0.024477222856135114,
      "acc_norm": 0.2623456790123457,
      "acc_norm_stderr": 0.024477222856135114
    },
    "hendrycksTest-professional_accounting": {
      "acc": 0.28368794326241137,
      "acc_stderr": 0.026891709428343957,
      "acc_norm": 0.28368794326241137,
      "acc_norm_stderr": 0.026891709428343957
    },
    "hendrycksTest-professional_law": {
      "acc": 0.24771838331160365,
      "acc_stderr": 0.011025499291443738,
      "acc_norm": 0.24771838331160365,
      "acc_norm_stderr": 0.011025499291443738
    },
    "hendrycksTest-professional_medicine": {
      "acc": 0.4411764705882353,
      "acc_stderr": 0.030161911930767102,
      "acc_norm": 0.4411764705882353,
      "acc_norm_stderr": 0.030161911930767102
    },
    "hendrycksTest-professional_psychology": {
      "acc": 0.238562091503268,
      "acc_stderr": 0.017242385828779613,
      "acc_norm": 0.238562091503268,
      "acc_norm_stderr": 0.017242385828779613
    },
    "hendrycksTest-public_relations": {
      "acc": 0.32727272727272727,
      "acc_stderr": 0.044942908662520875,
      "acc_norm": 0.32727272727272727,
      "acc_norm_stderr": 0.044942908662520875
    },
    "hendrycksTest-security_studies": {
      "acc": 0.39183673469387753,
      "acc_stderr": 0.031251275910891656,
      "acc_norm": 0.39183673469387753,
      "acc_norm_stderr": 0.031251275910891656
    },
    "hendrycksTest-sociology": {
      "acc": 0.2835820895522388,
      "acc_stderr": 0.031871875379197966,
      "acc_norm": 0.2835820895522388,
      "acc_norm_stderr": 0.031871875379197966
    },
    "hendrycksTest-us_foreign_policy": {
      "acc": 0.31,
      "acc_stderr": 0.04648231987117316,
      "acc_norm": 0.31,
      "acc_norm_stderr": 0.04648231987117316
    },
    "hendrycksTest-virology": {
      "acc": 0.24096385542168675,
      "acc_stderr": 0.033293941190735296,
      "acc_norm": 0.24096385542168675,
      "acc_norm_stderr": 0.033293941190735296
    },
    "hendrycksTest-world_religions": {
      "acc": 0.28654970760233917,
      "acc_stderr": 0.03467826685703826,
      "acc_norm": 0.28654970760233917,
      "acc_norm_stderr": 0.03467826685703826
    }
  },
  "versions": {
    "hendrycksTest-abstract_algebra": 1,
    "hendrycksTest-anatomy": 1,
    "hendrycksTest-astronomy": 1,
    "hendrycksTest-business_ethics": 1,
    "hendrycksTest-clinical_knowledge": 1,
    "hendrycksTest-college_biology": 1,
    "hendrycksTest-college_chemistry": 1,
    "hendrycksTest-college_computer_science": 1,
    "hendrycksTest-college_mathematics": 1,
    "hendrycksTest-college_medicine": 1,
    "hendrycksTest-college_physics": 1,
    "hendrycksTest-computer_security": 1,
    "hendrycksTest-conceptual_physics": 1,
    "hendrycksTest-econometrics": 1,
    "hendrycksTest-electrical_engineering": 1,
    "hendrycksTest-elementary_mathematics": 1,
    "hendrycksTest-formal_logic": 1,
    "hendrycksTest-global_facts": 1,
    "hendrycksTest-high_school_biology": 1,
    "hendrycksTest-high_school_chemistry": 1,
    "hendrycksTest-high_school_computer_science": 1,
    "hendrycksTest-high_school_european_history": 1,
    "hendrycksTest-high_school_geography": 1,
    "hendrycksTest-high_school_government_and_politics": 1,
    "hendrycksTest-high_school_macroeconomics": 1,
    "hendrycksTest-high_school_mathematics": 1,
    "hendrycksTest-high_school_microeconomics": 1,
    "hendrycksTest-high_school_physics": 1,
    "hendrycksTest-high_school_psychology": 1,
    "hendrycksTest-high_school_statistics": 1,
    "hendrycksTest-high_school_us_history": 1,
    "hendrycksTest-high_school_world_history": 1,
    "hendrycksTest-human_aging": 1,
    "hendrycksTest-human_sexuality": 1,
    "hendrycksTest-international_law": 1,
    "hendrycksTest-jurisprudence": 1,
    "hendrycksTest-logical_fallacies": 1,
    "hendrycksTest-machine_learning": 1,
    "hendrycksTest-management": 1,
    "hendrycksTest-marketing": 1,
    "hendrycksTest-medical_genetics": 1,
    "hendrycksTest-miscellaneous": 1,
    "hendrycksTest-moral_disputes": 1,
    "hendrycksTest-moral_scenarios": 1,
    "hendrycksTest-nutrition": 1,
    "hendrycksTest-philosophy": 1,
    "hendrycksTest-prehistory": 1,
    "hendrycksTest-professional_accounting": 1,
    "hendrycksTest-professional_law": 1,
    "hendrycksTest-professional_medicine": 1,
    "hendrycksTest-professional_psychology": 1,
    "hendrycksTest-public_relations": 1,
    "hendrycksTest-security_studies": 1,
    "hendrycksTest-sociology": 1,
    "hendrycksTest-us_foreign_policy": 1,
    "hendrycksTest-virology": 1,
    "hendrycksTest-world_religions": 1
  },
  "config": {
    "model": "llama-moe-causal",
    "model_args": "pretrained=/mnt/petrelfs/zhutong/smoe/outputs/cpt-moe-fpt-64gpus-bs16_2-zero1default-1600316/checkpoint-22000,use_accelerate=True",
    "num_fewshot": 5,
    "batch_size": "2",
    "batch_sizes": [],
    "device": null,
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {}
  }
}